{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0238b77-81bd-4ffb-aad8-adafabb1eb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found face 1 at top:240,right:816,bottom:388,left:668\n",
      "Found face 2 at top:124,right:420,bottom:272,left:268\n",
      "Found face 1 at top:240,right:816,bottom:388,left:668\n",
      "Found face 2 at top:124,right:420,bottom:272,left:268\n",
      "Found face 1 at top:224,right:816,bottom:372,left:668\n",
      "Found face 2 at top:124,right:420,bottom:272,left:268\n",
      "Found face 1 at top:228,right:804,bottom:352,left:680\n",
      "Found face 2 at top:124,right:404,bottom:272,left:252\n",
      "Found face 1 at top:124,right:404,bottom:272,left:252\n",
      "Found face 2 at top:228,right:804,bottom:352,left:680\n",
      "Found face 1 at top:124,right:404,bottom:272,left:252\n",
      "Found face 2 at top:228,right:804,bottom:352,left:680\n",
      "Found face 1 at top:124,right:404,bottom:272,left:252\n",
      "Found face 2 at top:228,right:804,bottom:352,left:680\n",
      "Found face 1 at top:124,right:404,bottom:272,left:252\n",
      "Found face 2 at top:228,right:804,bottom:352,left:680\n",
      "Found face 1 at top:108,right:404,bottom:256,left:252\n",
      "Found face 2 at top:228,right:816,bottom:352,left:692\n",
      "Found face 1 at top:88,right:404,bottom:268,left:228\n",
      "Found face 2 at top:228,right:816,bottom:352,left:692\n",
      "Found face 1 at top:108,right:388,bottom:256,left:236\n",
      "Found face 2 at top:228,right:816,bottom:352,left:692\n",
      "Found face 1 at top:108,right:388,bottom:256,left:236\n",
      "Found face 2 at top:228,right:816,bottom:352,left:692\n",
      "Found face 1 at top:228,right:816,bottom:352,left:692\n",
      "Found face 2 at top:108,right:384,bottom:288,left:208\n",
      "Found face 1 at top:108,right:384,bottom:288,left:208\n",
      "Found face 2 at top:228,right:816,bottom:352,left:692\n",
      "Found face 1 at top:128,right:364,bottom:308,left:188\n",
      "Found face 2 at top:208,right:832,bottom:356,left:684\n",
      "Found face 1 at top:208,right:832,bottom:356,left:684\n",
      "Found face 2 at top:148,right:344,bottom:328,left:168\n",
      "Found face 1 at top:208,right:832,bottom:356,left:684\n",
      "Found face 2 at top:168,right:324,bottom:348,left:148\n",
      "Found face 1 at top:224,right:832,bottom:372,left:684\n",
      "Found face 2 at top:188,right:284,bottom:368,left:108\n",
      "Found face 1 at top:224,right:832,bottom:372,left:684\n",
      "Found face 2 at top:180,right:272,bottom:396,left:60\n",
      "Found face 1 at top:224,right:832,bottom:372,left:684\n",
      "Found face 1 at top:208,right:832,bottom:356,left:684\n",
      "Found face 1 at top:208,right:832,bottom:356,left:684\n",
      "Found face 1 at top:212,right:832,bottom:336,left:708\n",
      "Found face 1 at top:212,right:832,bottom:336,left:708\n",
      "Found face 1 at top:188,right:832,bottom:340,left:684\n",
      "Found face 1 at top:188,right:832,bottom:340,left:684\n",
      "Found face 1 at top:188,right:832,bottom:340,left:684\n",
      "Found face 1 at top:188,right:832,bottom:340,left:684\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9968\\1427666671.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m#detect all faces in the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#arguments are image,no_of_times_to_upsample, model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mall_face_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_frame_small\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hog'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#looping through the face locations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-31040\\python-3.10.4.amd64\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\WPy64-31040\\python-3.10.4.amd64\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: abhilash\n",
    "\"\"\"\n",
    "\n",
    "#importing the required libraries\n",
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "#capture the video from default camera \n",
    "file_video_stream = cv2.VideoCapture('Joe Taslim x Fadil Jaidi.mp4')\n",
    "\n",
    "#initialize the array variable to hold all face locations in the frame\n",
    "all_face_locations = []\n",
    "\n",
    "#loop through every frame in the video\n",
    "while (file_video_stream.isOpened):\n",
    "    #get the current frame from the video stream as an image\n",
    "    ret,current_frame = file_video_stream.read()\n",
    "    #resize the current frame to 1/4 size to proces faster\n",
    "    current_frame_small = cv2.resize(current_frame,(0,0),fx=0.25,fy=0.25)\n",
    "    #detect all faces in the image\n",
    "    #arguments are image,no_of_times_to_upsample, model\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small,number_of_times_to_upsample=2,model='hog')\n",
    "    \n",
    "    #looping through the face locations\n",
    "    for index,current_face_location in enumerate(all_face_locations):\n",
    "        #splitting the tuple to get the four position values of current face\n",
    "        top_pos,right_pos,bottom_pos,left_pos = current_face_location\n",
    "        #change the position maginitude to fit the actual size video frame\n",
    "        top_pos = top_pos*4\n",
    "        right_pos = right_pos*4\n",
    "        bottom_pos = bottom_pos*4\n",
    "        left_pos = left_pos*4\n",
    "        #printing the location of current face\n",
    "        print('Found face {} at top:{},right:{},bottom:{},left:{}'.format(index+1,top_pos,right_pos,bottom_pos,left_pos))\n",
    "        #draw rectangle around the face detected\n",
    "        cv2.rectangle(current_frame,(left_pos,top_pos),(right_pos,bottom_pos),(0,0,255),2)\n",
    "    #showing the current face with rectangle drawn\n",
    "    cv2.imshow(\"Webcam Video\",current_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "#release the stream and cam\n",
    "#close all opencv windows open\n",
    "file_video_stream.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b533ea-2456-4a96-9231-193ea4b4a974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
